version: "3.3"
services:
  ffserver:
    build: ./ffserver
    restart: always
    expose:
      - "3004"
    volumes:
      - ./resources:/resources
    ports:
      - "3004:3004"
    networks:
      - project-network  
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://ffserver:3004/stat.html --max-time 1 --output /dev/null || exit 1"]
      interval: 15s
      timeout: 1s
      retries: 3
  webserver:
    build: ./webserver
    ports:
      - 3001:3001
      - 3002:3002
    networks:
      - project-network
    command: npm run start
  webui:
    build: ./webui
    ports:
      - 3000:3000
    networks:
      - project-network
    depends_on:
      - webserver
      - ffserver
    command: npm run dev
    env_file: ./webui/.env
      
  inferemce:
    build:
      context: ./inference
      dockerfile: Dockerfile
    ports:
      - 3003:3003
    env_file: ./inference/.env
    networks:
      - project-network
    depends_on:
      - webserver
    restart: on-failure
    volumes:
      - "./inference/wait-for-it.sh:/app/wait-for-it.sh"
      - "./inference/app/main.py:/app/main.py"
      - "./inference/app/inference.py:/app/inference.py"
      - "./inference/data:/app/data"
      - "./inference/run-inference-commands.sh:/app/run-inference-commands.sh"
    command:
      [
        "/app/wait-for-it.sh",
        "webserver:3001",
        "--",
        "/app/run-inference-commands.sh",
      ]

networks:
  project-network:
    driver: bridge
